#!/usr/bin/env python
#
# Cloudlet Infrastructure for Mobile Computing
#
#   Author: Thomas Eiszler <teiszler@andrew.cmu.edu>
#
#   Copyright (C) 2011-2019 Carnegie Mellon University
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

from __future__ import division
import argparse
import datetime
import errno
import json
import glob
import libvirt
from libvirt import libvirtError
from lxml import etree
import msgpack
import os
import random
import shutil
import signal
import subprocess
import sys
from tempfile import NamedTemporaryFile
import textwrap
import threading
import time
from uuid import uuid4
import zipfile
from fabric.api import run,env
import logging
import logging.config
import json

from elijah.provisioning import synthesis as synthesis
from elijah.provisioning import compression as compression
from elijah.provisioning.configuration import Const as Const
from elijah.provisioning.configuration import Options
import elijah.provisioning.db.table_def as table_def
from elijah.provisioning.db.api import DBConnector, log_op, update_op
from elijah.provisioning.package import PackagingUtil

URI_TEMPLATE = 'qemu:///system'
DIR_NEPHELE = '/var/nephele/'
DIR_NEPHELE_IMAGES = '/var/nephele/images/'
DIR_NEPHELE_SNAPSHOTS = '/var/nephele/snapshots/'

with open('/var/nephele/logging.json') as f:
    config_dict = json.load(f)
    logging.config.dictConfig(config_dict)

LOG = logging.getLogger(__name__)

# Squash redundant reporting of libvirt errors to stderr.  This modifies
# global state, since the Python bindings don't provide a way to do this
# per-connection.
libvirt.registerErrorHandler(lambda _ctx, _error: None, None)

def check_and_convert_to_raw(path):
    #qemu_img info <path>
    #scan for raw
    pass

def build_base(args):
    source = args.path
    disk_image_path = DIR_NEPHELE_IMAGES + source[source.rindex('/'):]

    # check if this filename already exists and warn
    if os.path.exists(disk_image_path):
        if not raw_input("An image with this filename already exists.\nAre you sure you wish to overwrite the following base image: %s? (y/N): " % (disk_image_path)).lower().strip().startswith("y"):
            sys.exit(1)
        if not raw_input("This will render any snapshots based on this image unusable. Are you certain? (y/N): ").lower().strip().startswith("y"):
            sys.exit(1)
    op_id = log_op(op=Const.OP_BUILD_IMAGE,notes="Source: %s" % (source))
    LOG.info("Copying/converting source image into %s..." % DIR_NEPHELE_IMAGES)
    os.system('qemu-img convert -O raw %s %s' % (source, disk_image_path))

    disk_path, mem_path = synthesis.create_baseVM(disk_image_path, source=source, title=args.title, cpus=args.cpu, mem=args.mem)
    LOG.info( "Created Base VM from this source image: %s" % source)
    LOG.info( "Base Disk Image: %s" % disk_path)
    LOG.info( "Base Memory Snapshot: %s" % mem_path)
    update_op(op_id, has_ended=True, notes="Source: %s, Path: %s" % (source, disk_image_path))

    #restart the stream-server to reload list of images
    os.system('service stream-server restart')

def find_base(id):
    base = None
    dbconn = DBConnector()
    list = dbconn.list_item(table_def.BaseVM)
    for item in list:
        if id == item.hash_value[:12]:
            base = item
            break
    return dbconn, base

def build_snapshot(args):
    try:
        options = Options()
        options.DISK_ONLY = args.disk_only
        options.TRIM_SUPPORT = not args.no_trim
        options.FREE_SUPPORT = args.free_mem
        options.ZIP_CONTAINER = args.zip

        _, base = find_base(args.id)
        if base is None:
            LOG.error( "Failed to find matching image with id: %s" % args.id)
            return
        vm_overlay = synthesis.VM_Overlay(base.disk_path, options,
                                            qemu_args=None)
        machine = vm_overlay.resume_basevm(args.title)
        LOG.info( 'Launching VM...\nPause VM when finished modifying to begin hashing of disk/memory state.')
        #wait until VM is paused
        while True:
            state, _ = machine.state()
            if state == libvirt.VIR_DOMAIN_PAUSED:
                break
        LOG.info( 'VM entered paused state. Generating snapshot of disk and memory...' )
        op_id = log_op(op=Const.OP_BUILD_SNAPSHOT,notes="Image: %s, Dest: %s" % (args.id, args.dest))
        vm_overlay.create_overlay()

        # print output
        if args.zip is False:
            LOG.debug("overlay metafile (%ld) : %s\n" %
                                (os.path.getsize(vm_overlay.overlay_metafile),
                                vm_overlay.overlay_metafile))
            for overlay_file in vm_overlay.overlay_files:
                LOG.debug("overlay (%ld) : %s\n" %
                    (os.path.getsize(overlay_file), overlay_file))
        else:
            overlay_zip = zipfile.ZipFile(vm_overlay.overlay_zipfile)
            filesize_count = 0
            for zipinfo in overlay_zip.infolist():
                if zipinfo.filename == Const.OVERLAY_META:
                    msg = "meta file : (%ld) bytes\n" % \
                        (zipinfo.file_size)
                else:
                    msg = "blob file : (%ld) bytes (%s)\n" % \
                        (zipinfo.file_size, zipinfo.filename)
                filesize_count += zipinfo.file_size
                LOG.debug(msg)
            LOG.debug(
                "zip overhead : (%ld) bytes\n" %
                (os.path.getsize(vm_overlay.overlay_zipfile) - filesize_count))
    except Exception as e:
        LOG.error( "Failed to create overlay: %s" % str(e))
    os.rename(vm_overlay.overlay_zipfile, args.dest)
    update_op(op_id, has_ended=True)
    # save the result to DB
    dbconn = DBConnector()
    list = dbconn.list_item(table_def.Snapshot)
    for item in list:
        if args.dest == item.path:
            dbconn.del_item(item)
            break
    new = table_def.Snapshot(args.dest, base.hash_value)
    dbconn.add_item(new)

def list_base(args):
    dbconn = DBConnector()
    list = dbconn.list_item(table_def.BaseVM)
    print "{:<12}{:^8}{:<43}{:^8}{:<43}".format('IMAGE ID','', 'NAME (/var/nephele/images/)', '', 'SOURCE')
    for item in list:
        print "{:<12}{:^8}{:<43}{:^8}{:<43}".format(item.hash_value[:12],'', item.disk_path[item.disk_path.rindex('/')+1:], '', item.source)
        str.rindex

def list_snapshots(args):
    dbconn = DBConnector()
    list = dbconn.list_item(table_def.Snapshot)
    print "{:<43}{:^8}{:<12}{:^8}{:<43}".format('SNAPSHOT', '','IMAGE ID', '','CREATED')
    for item in list:
        print "{:<43}{:^8}{:<12}{:^8}{:<43}".format(item.path, '', item.basevm[:12], '', str(item.create_time))

def list_instances(args):
    dbconn = DBConnector()
    list = dbconn.list_item(table_def.Instances)
    print "{:<43}{:^8}{:<12}{:^8}{:<43}".format('TITLE', '','PID', '','STARTED')
    for item in list:
        print "{:<43}{:^8}{:<12}{:^8}{:<43}".format(item.title, '', item.pid, '', str(item.start_time))

def remote_execution(host, nohup=False):
        env.host_string = 'root@%s' % host
        env.output_prefix = False
        sys.argv.remove('-r')
        sys.argv.remove(host)
        cmd = ' '.join(sys.argv)
        if nohup:
            cmd = "nohup " + cmd
        #print "Executing %s on %s" % (cmd, host)
        run(cmd)

def show_logs(args):
    dbconn = DBConnector()
    if(args.all):
        list = dbconn.session.query(table_def.Operations).order_by(table_def.Operations.id.desc())
    else:
        list = dbconn.session.query(table_def.Operations).order_by(table_def.Operations.id.desc()).limit(10)
    print "{:<16}{:^8}{:<18}{:^8}{:<18}{:^8}{:<30}".format('OPERATION', '','STARTED', '','FINISHED', '', 'DETAILS')
    for item in list:
        print "{:<16}{:^8}{:<18}{:^8}{:<18}{:^8}{:<30}".format(item.op, '', str(item.start_time)[:-7], '', str(item.end_time)[:-7], '', item.notes)

def delete_snapshot(args):
    dbconn = DBConnector()
    if args.path:
        path = os.path.abspath(args.path)
    list = dbconn.list_item(table_def.Snapshot)
    snapshot = None
    for item in list:
        if (path == item.path):
            snapshot = item
            break
    if snapshot is not None:
        if raw_input("Are you sure you wish to delete the following snapshot: %s? (y/N): " % (args.path)).lower().strip().startswith("y"):
            op_id = log_op(op=Const.OP_DELETE_SNAPSHOT,notes="Snapshot: %s" % (args.path))
            dbconn.del_item(snapshot)
            LOG.info( "Snapshot removed from database." )
            os.remove(args.path)
            LOG.info( "Snapshot deleted from disk." )
            update_op(op_id, has_ended=True)
    else:
        LOG.error( "Cannot find matching snapshot at path %s\n" % (args.path) )
        return 1

def clear_instances(args):
    if args.force or raw_input("Are you sure you wish to clear data? (y/N): ").lower().strip().startswith("y"):
        dbconn = DBConnector()
        if args.instances:
            list = dbconn.list_item(table_def.Instances)
            for item in list:
                dbconn.del_item(item)
            LOG.info( "Cleared instances table." )
        if args.operations:
            list = dbconn.list_item(table_def.Operations)
            for item in list:
                dbconn.del_item(item)
            LOG.info( "Cleared operations table." )
    return 0

def delete_base(args):
    dbconn, base = find_base(args.id)
    if base is None:
        LOG.error( "Failed to find matching image with id: %s" % args.id )
        return
    else:
        if raw_input("Are you sure you wish to delete the following base image: %s? (y/N): " % (base.disk_path)).lower().strip().startswith("y"):
            if raw_input("This will render any snapshots based on this image unusable. Are you certain? (y/N): ").lower().strip().startswith("y"):
                op_id = log_op(op=Const.OP_DELETE_IMAGE,notes="Image: %s, Path: %s" % (args.id, base.disk_path))
                dbconn.del_item(base)
                LOG.info( "Image removed from database." )
                ext = str(base.disk_path).rindex('.')
                for f in glob.glob(base.disk_path[:ext] + '*'):
                    os.remove(f)
                LOG.info( "Image deleted from disk." )
                update_op(op_id, has_ended=True)
                

def export_base(args):
    _, base = find_base(args.id)

    output_path = args.dest
    if base is not None:
        op_id = log_op(op=Const.OP_EXPORT_IMAGE,notes="Image: %s, Dest: %s" % (args.id, args.dest))
        PackagingUtil.export_basevm(
            output_path,
            base.disk_path,
            base.hash_value)
        update_op(op_id, has_ended=True)
    else:
        LOG.error( "Failed to find matching image with id: %s" % args.id )

def import_base(args):
    source = args.path
    if os.path.exists(source) == False or os.access(source, os.R_OK) == False:
        LOG.error( "Cannot read file: %s" % source )
        return 1
   
    (base_hashvalue, disk_name, memory_name, diskhash_name, memoryhash_name) = \
            PackagingUtil._get_basevm_attribute(source)
    disk_image_path = DIR_NEPHELE_IMAGES + disk_name

    # check if this filename already exists and warn
    if os.path.exists(disk_image_path):
        if not raw_input("An image with this filename already exists.\nAre you sure you wish to overwrite the following base image: %s? (y/N): " % (disk_image_path)).lower().strip().startswith("y"):
            sys.exit(1)
        if not raw_input("This will render any snapshots based on this image unusable. Are you certain? (y/N): ").lower().strip().startswith("y"):
            sys.exit(1)
    op_id = log_op(op=Const.OP_IMPORT_IMAGE,notes="Image Path: %s" % (args.path))
    LOG.info( "Decompressing image to %s..." % DIR_NEPHELE_IMAGES )
    zipbase = zipfile.ZipFile(source, 'r')
    zipbase.extractall(DIR_NEPHELE_IMAGES)
    LOG.info( "Extracted image files to %s." % (disk_image_path) )

    # add to DB
    new_basevm = table_def.BaseVM(disk_image_path, base_hashvalue, source)
    dbconn = DBConnector()
    dbconn.add_item(new_basevm)
    update_op(op_id, has_ended=True)

     #restart the stream-server to reload list of images
    os.system('service stream-server restart')

def import_snapshot(args):
    if not os.path.exists(args.path):
        LOG.error( "Snapshot path (%s) does not exist!" % (args.path) )
    else:
        url = 'file://' + os.path.abspath(args.path)
        overlay_filename = NamedTemporaryFile(prefix="cloudlet-overlay-file-")
        meta_info = compression.decomp_overlayzip(url, overlay_filename.name)

        base_sha = meta_info[Const.META_BASE_VM_SHA256]
        base_found = False
        dbconn = DBConnector()
        basevm_list = dbconn.list_item(table_def.BaseVM)
        for basevm_row in basevm_list:
            if basevm_row.hash_value == base_sha:
                base_found = True
                break
        if not base_found:
            LOG.error( "Cannot find base image (SHA-256: %s) referenced in overlay: %s" % (base_sha, args.path) )

        # save the result to DB
        list = dbconn.list_item(table_def.Snapshot)
        for item in list:
            if args.path == item.path:
                dbconn.del_item(item)
                break
        new = table_def.Snapshot(args.path, basevm_row.hash_value)
        dbconn.add_item(new)

def synthesize(args):
        if os.fork():
            os._exit(0)
        overlay_meta = args.snapshot
        is_zip_contained, url_path = PackagingUtil.is_zip_contained(
            overlay_meta)
        if is_zip_contained is True:
            overlay_meta = url_path
        try:
            # save the instance info to DB
            dbconn = DBConnector()
            new = table_def.Instances(args.title, os.getpid())
            dbconn.add_item(new)

            synthesis.synthesize(None, overlay_meta,
                                disk_only=args.disk_only,
                                handoff_url=None,
                                zip_container=is_zip_contained,
                                title=args.title,
                                fwd_ports=args.ports)
        except Exception as e:
            LOG.error( "Failed to synthesize: %s" % str(e) )
            return 1
        finally:
            dbconn = DBConnector()
            list = dbconn.list_item(table_def.Instances)
            for item in list:
                if args.title == item.title:
                    dbconn.del_item(item)
                    break

def snapshot_details(args):
        try:
            output = synthesis.info_vm_overlay(args.path)
            print("\n")
            print(output)
        except Exception as e:
            print(str(e))
            return 1

def handoff(args):
    handoff_url = 'tcp://' + args.dest + ':8022'

    dbconn = DBConnector()
    list = dbconn.list_item(table_def.Instances)
    instance = None
    for item in list:
        if (args.title == item.title):
            instance = item
            break
    if instance is not None:
        #send USR1 to that process and put the destination into a temp file for reading
        fdest = open('/tmp/%s.cloudlet-handoff' % item.pid, "wb")
        meta = dict()
        meta['title'] = item.title
        meta['pid'] = item.pid
        meta['url'] = handoff_url
        fdest.write(msgpack.packb(meta))
        fdest.close()
        os.kill(item.pid, signal.SIGUSR1)
    else:
        LOG.error( 'Cannot find a running instance with the title [%s]!' % args.title )

def print_args(args):
    print args

def _main():
    parser = argparse.ArgumentParser(prog='nephele', description='Manage VMs across cloudlets.')
    parser.add_argument('-r', '--remote', help="Execute commands on specified remote host.")
    subparsers = parser.add_subparsers(title='command', dest="command")

    list_instances_parser = subparsers.add_parser('ls', help='List running nephele instances')
    list_instances_parser.set_defaults(func=list_instances)

    operations_parser = subparsers.add_parser('logs', help='List logs of nephele operations performed.')
    operations_parser.add_argument('-a', '--all', action='store_true', help='Show all rows (default: last 10')
    operations_parser.set_defaults(func=show_logs)

    base_parser = subparsers.add_parser('image', help='Management of base VM images')
    base_subparsers = base_parser.add_subparsers(title='base')
    build_parser = base_subparsers.add_parser('build', help='Build a base image from an existing raw disk image')
    build_parser.add_argument('path', help='Path to an existing base image in raw format')
    build_parser.add_argument('-t', '--title',  help='Title of the VM instance to display')
    build_parser.add_argument('-c', '--cpu', type=int, help='Override number of vCPUs. By default, the number specified in the VM_TEMPLATE.xml will be used.')
    build_parser.add_argument('-m', '--mem', type=int, help='Override amount of memory (in KiB). By default, the number specified in the VM_TEMPLATE.xml will be used.')
    build_parser.set_defaults(func=build_base)

    export_parser = base_subparsers.add_parser('export', help='Export a zip file containing a compressed base image')
    export_parser.add_argument('id', help='ID of base image to export')
    export_parser.add_argument('dest', help='destination of exported zip file')
    export_parser.set_defaults(func=export_base)

    import_parser = base_subparsers.add_parser('import', help='Import a base image from a compressed zip file')
    import_parser.add_argument('path', help='an existing zip file containing a base image')
    import_parser.set_defaults(func=import_base)

    list_base_parser = base_subparsers.add_parser('ls', help='List base images tracked by Nephele')
    list_base_parser.set_defaults(func=list_base)

    delete_base_parser = base_subparsers.add_parser('rm', help='Remove a base image from Nephele')
    delete_base_parser.add_argument('id', help='ID of base image to remove')
    delete_base_parser.set_defaults(func=delete_base)

    snapshot_parser = subparsers.add_parser('snapshot', help='Management of VM snapshots')
    snapshot_subparsers = snapshot_parser.add_subparsers(title='snapshot')

    build_snapshot_parser = snapshot_subparsers.add_parser('build', help='Interact with a base VM to create a new snapshot')
    build_snapshot_parser.add_argument('id', help='an existing base image to start with')
    build_snapshot_parser.add_argument('dest', help='Destination path for snapshot')
    build_snapshot_parser.add_argument('-t', '--title',  help='Title of the VM instance to display')
    build_snapshot_parser.add_argument('-d', '--disk-only', action='store_true',  help='Ignore memory, create delta from disk blocks only. (default=False)')
    build_snapshot_parser.add_argument('-m', '--free-mem', action='store_true', help='Extract free memory (default=False)')
    build_snapshot_parser.add_argument('-n', '--no-trim', action='store_true', help='Disable TRIM support. (default=False)')
    build_snapshot_parser.add_argument('-z', '--zip', default=True, action='store_true', help='Package snapshot files into a single zip. (default=True))')
    build_snapshot_parser.set_defaults(func=build_snapshot)

    import_snapshot_parser = snapshot_subparsers.add_parser('import', help='Import a snapshot from a compressed zip file')
    import_snapshot_parser.add_argument('path', help='an existing zip file containing a snapshot')
    import_snapshot_parser.set_defaults(func=import_snapshot)

    inspect_parser = snapshot_subparsers.add_parser('inspect', help='Output details of a snapshot')
    inspect_parser.add_argument('path', help='Path to an existing snapshot to inspect')
    inspect_parser.set_defaults(func=snapshot_details)

    list_snapshot_parser = snapshot_subparsers.add_parser('ls', help='List snapshots known to nephele')
    list_snapshot_parser.set_defaults(func=list_snapshots)

    delete_snapshot_parser = snapshot_subparsers.add_parser('rm', help='Remove a snapshot from nephele')
    delete_snapshot_parser.add_argument('path', help='Path of snapshot to remove')
    delete_snapshot_parser.set_defaults(func=delete_snapshot)

    run_parser = subparsers.add_parser('run',
            help='Instantiate a VM from an existing snapshot')
    run_parser.add_argument('snapshot', help='Disk/memory snapshot to instantiate from')
    run_parser.add_argument('title',  help='Title of the VM instance to display')
    run_parser.add_argument('-d', '--disk-only', action='store_true',  help='Ignore memory, create delta from disk blocks only. (default=False)')
    run_parser.add_argument('-p', '--ports', help='Comma separated list of ports to forward from host to guest. -p 80,443,8080,8443')
    run_parser.set_defaults(func=synthesize)

    handoff_parser = subparsers.add_parser('handoff', help='Handoff a running instance to another node')
    handoff_parser.add_argument('title',  help='Title of the VM instance to handoff')
    handoff_parser.add_argument('dest', help='Handoff destination - IP address or DNS name.')
    handoff_parser.set_defaults(func=handoff)

    clear_parser = subparsers.add_parser('clear', help='Clear tables')
    clear_parser.add_argument('-i', '--instances', action='store_true',  help='Clear table of running instances. Usually only necessary if handoff fails.')
    clear_parser.add_argument('-o', '--operations', action='store_true',  help='Clear table of logged operations.')
    clear_parser.add_argument('-f', '--force', action='store_true',  help='Do not prompt for confirmation.')
    clear_parser.set_defaults(func=clear_instances)

    if len(sys.argv) == 1:
        parser.print_help()
    args = parser.parse_args()
    if(args.remote is not None):
        if(args.command == 'run'):
            remote_execution(args.remote, nohup=True)
        else:
            remote_execution(args.remote)
    else: #local execution
        ret = args.func(args) or 0
        sys.exit(ret)

if __name__ == '__main__':
    _main()
